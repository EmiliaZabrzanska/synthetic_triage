import streamlit as st
import pandas as pd
from synthcity.plugins import Plugins
from synthcity.metrics.eval import Metrics
from synthcity.plugins.core.dataloader import GenericDataLoader
from sklearn.ensemble import RandomForestClassifier
import shap
import matplotlib.pyplot as plt

"""
Part 1: Synthetic data generation and model training
"""

@st.cache_resource
def load_model():
    """
    Loads the seed data from CSV, generates synthetic data, 
    and trains the model. Returns all artifacts needed for the app.
    """
    # 1. Load Seed Data from CSV
    try:
        seed_df = pd.read_csv("seed_data.csv")
        print("Loaded seed data from CSV successfully.")
    except FileNotFoundError:
        st.error("Could not find 'seed_data.csv'. Please ensure it is in the same folder as app.py")
        st.stop()

    # 2. Generate Synthetic Data
    # We pass the seed_df directly to the loader
    loader = GenericDataLoader(seed_df, target_column="outcome")
    
    syn_model = Plugins().get("ctgan")
    print("Fitting synthetic data generator...")
    syn_model.fit(loader)

    print("Generating 10000 new synthetic patients...")
    synthetic_data = syn_model.generate(count=10000)
    synthetic_df = synthetic_data.dataframe()

    # 3. Train Triage Model
    print("Training triage model...")
    X_train = synthetic_df.drop('outcome', axis=1)
    y_train = synthetic_df['outcome']
    
    model = RandomForestClassifier(n_estimators=200, random_state=42)
    model.fit(X_train, y_train)
    
    # 4. Return EVERYTHING we need
    # We return seed_df and synthetic_df so we can use them in Part 5
    return model, seed_df.columns.drop('outcome'), seed_df, synthetic_df

"""
Part 2: Streamlit App for Triage Prediction
"""

# Load the trained model (it will be cached after the first run)
# Note: it now returns the model AND the feature names
model, feature_names, seed_df, synthetic_df = load_model()

# Set up the title and a description
st.title("ðŸ©º Synthetic Triage Prediction App (v2)")
st.write(
    "This app predicts a triage outcome based on patient symptoms. "
    "The model was trained on **100% synthetic data** generated by `synthcity`, "
    "from a **seed dataset**."
)
st.write("---")

# --- Create the input controls in the sidebar ---
st.sidebar.header("Enter Patient Symptoms:")

# 1. Age Slider
age = st.sidebar.slider("What is the patient's age?", 0, 100, 25)

# 2. Days Sick Slider
days_sick = st.sidebar.slider("How many days has the patient been sick?", 0, 14, 3)

# 3. NEW: Pain Severity Slider
pain_severity = st.sidebar.slider("On a scale of 0-10, what is the pain severity?", 0, 10, 2)

# 4. Yes/No Selectors
fever = st.sidebar.selectbox("Does the patient have a fever?", ("No", "Yes"))
cough = st.sidebar.selectbox("Does the patient have a cough?", ("No", "Yes"))
chest_pain = st.sidebar.selectbox("Is the patient experiencing chest pain?", ("No", "Yes"))
breathing_difficulty = st.sidebar.selectbox("Is the patient having breathing difficulty?", ("No", "Yes"))
has_asthma = st.sidebar.selectbox("Does the patient have a history of asthma?", ("No", "Yes"))


'''
Part 3: Prediction and Display
'''

# 1. Convert text inputs to numbers (1s and 0s)
fever_int = 1 if fever == "Yes" else 0
cough_int = 1 if cough == "Yes" else 0
chest_pain_int = 1 if chest_pain == "Yes" else 0
breathing_difficulty_int = 1 if breathing_difficulty == "Yes" else 0
has_asthma_int = 1 if has_asthma == "Yes" else 0

# 2. Create a dictionary of the inputs
input_dict = {
    'age': age,
    'fever': fever_int,
    'cough': cough_int,
    'chest_pain': chest_pain_int,
    'breathing_difficulty': breathing_difficulty_int,
    'days_sick': days_sick,
    'has_asthma': has_asthma_int,
    'pain_severity': pain_severity
}

# 3. Create a DataFrame from the inputs
input_data = pd.DataFrame([input_dict], columns=feature_names)

# 4. Make the prediction and get probabilities
prediction = model.predict(input_data)[0]
prediction_proba = model.predict_proba(input_data)

# 5. Display the results
st.subheader("Model Recommendation")

# Use st.metric for a display
if prediction == 'go_to_a&e':
    st.metric(label="Predicted Outcome", value=prediction, delta="High Urgency", delta_color="off")
    st.error("Recommendation: Seek urgent medical attention.")
elif prediction == 'see_gp':
    st.metric(label="Predicted Outcome", value=prediction, delta="Medium Urgency", delta_color="off")
    st.warning("Recommendation: Contact a GP or local healthcare provider.")
else:
    st.metric(label="Predicted Outcome", value=prediction, delta="Low Urgency", delta_color="inverse")
    st.success("Recommendation: Monitor symptoms and use self-care.")

# Display the raw inputs
st.subheader("Patient Data Entered:")
st.dataframe(input_data)

# Display the confidence scores (this is a great addition)
st.subheader("Prediction Confidence Scores")
proba_df = pd.DataFrame(prediction_proba, columns=model.classes_)
proba_df_transposed = proba_df.T.rename(columns={0: 'Confidence'})
st.bar_chart(proba_df_transposed)

'''
Part 4: Explainable AI (SHAP) 
'''

st.write("---")
st.subheader("ðŸ¤– Explainability (Why did the model say that?)")

if st.checkbox("Show detailed explanation"):
    with st.spinner("Calculating feature importance..."):
        
        # 1. Create a TreeExplainer
        explainer = shap.TreeExplainer(model)
        
        # 2. Calculate SHAP values
        shap_values = explainer.shap_values(input_data)
        
        # 3. Find the index of the predicted class
        prediction_index = list(model.classes_).index(prediction)
        
        # 4. Extract the values safely (Handling List vs. Array formats)
        if isinstance(shap_values, list):
            # Old SHAP behavior: List of arrays [Class 0, Class 1, Class 2]
            # We pick the array for our class (prediction_index), then the 0th row (our patient)
            shap_val_for_prediction = shap_values[prediction_index][0]
        else:
            # New SHAP behavior: Single 3D Array (Samples, Features, Classes)
            # We pick Sample 0, All Features (:), and our specific Class (prediction_index)
            # Note: Sometimes shape is just (Samples, Features) if binary.
            if len(shap_values.shape) == 3:
                shap_val_for_prediction = shap_values[0, :, prediction_index]
            else:
                # Fallback for binary cases where it might return just the positive class
                shap_val_for_prediction = shap_values[0]
        
        # 5. Create DataFrame for plotting
        explanation_df = pd.DataFrame({
            'Feature': feature_names,
            'Contribution': shap_val_for_prediction
        }).sort_values(by='Contribution', ascending=True)
        
        # 6. Plot
        fig, ax = plt.subplots(figsize=(8, 5))
        
        # Red = Pushing towards this outcome, Blue = Pushing away
        colors = ['#ff4b4b' if x > 0 else '#1f77b4' for x in explanation_df['Contribution']]
        
        ax.barh(explanation_df['Feature'], explanation_df['Contribution'], color=colors)
        ax.set_xlabel(f"Contribution to '{prediction}' Prediction")
        ax.set_title(f"Which symptoms pushed the result towards '{prediction}'?")
        ax.axvline(x=0, color='black', linestyle='--', linewidth=0.8)
        
        st.pyplot(fig)
        
        st.info(
            """
            **How to read this graph:**
            * **Red Bars (Right):** These symptoms **increased** the likelihood of this outcome.
            * **Blue Bars (Left):** These symptoms **decreased** the likelihood.
            """
        )

'''
Part 5: Research Evaluation (The "Proof")
'''
st.write("---")
st.header("ðŸ“Š Research Evaluation Report")
st.write(
    "This section compares the **Real Seed Data** (loaded from `seed_data.csv`) "
    "with the **Synthetic Data** generated by `synthcity`."
)

if st.button("Run Data Quality Evaluation"):
    
    with st.spinner("Running evaluation metrics..."):
        
        # 1. Wrap our PRE-LOADED dataframes into DataLoaders
        # We don't need to re-generate anything!
        loader_real = GenericDataLoader(seed_df, target_column="outcome")
        loader_fake = GenericDataLoader(synthetic_df, target_column="outcome")

        # 2. Run the Metrics
        evaluation = Metrics.evaluate(
            loader_real,
            loader_fake,
            metrics={
                'stats': ['jensenshannon_distance', 'chi_squared_test', 'inverse_kl_divergence']
            }
        )
    
    # --- Display Results ---
    st.subheader("1. Statistical Similarity")
    st.table(evaluation)
    
    st.info(
        """
        **Interpretation:**
        * **Jensen-Shannon Distance:** Measures difference. Closer to 0 is better.
        * **Chi-Squared:** P-value > 0.05 usually indicates good fit (hard to achieve with small data).
        """
    )

    # --- Visual Comparison ---
    st.subheader("2. Visual Distribution Check")
    st.write("Comparing 'Age' distribution: Real (Blue) vs. Synthetic (Orange)")
    
    fig, ax = plt.subplots()
    # We use density=True to compare shapes even though sample sizes are different (26 vs 5000)
    ax.hist(seed_df['age'], density=True, alpha=0.5, label='Real (Seed)', bins=10)
    ax.hist(synthetic_df['age'], density=True, alpha=0.5, label='Synthetic', bins=10)
    ax.legend()
    st.pyplot(fig)